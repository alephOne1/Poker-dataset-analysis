{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявление констант с неизменной информацией о загружаемых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "URL_TO_TRAIN_DATA = r\"http://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-training-true.data\"\n",
    "URL_TO_TEST_DATA = r\"http://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-testing.data\"\n",
    "\n",
    "indexes = []\n",
    "for index in range(1, 6):\n",
    "    indexes.append(index)\n",
    "    indexes.append(index)\n",
    "\n",
    "COLUMNS_NAMES = [\n",
    "    (letter + str(index)).lower() for letter, index in zip(\n",
    "        [\"S\", \"C\"] * 5,\n",
    "        indexes\n",
    "    )\n",
    "] + [\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных обучающей выборки средствами *Pandas*, вывод первых 5 строк таблицы на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>c1</th>\n",
       "      <th>s2</th>\n",
       "      <th>c2</th>\n",
       "      <th>s3</th>\n",
       "      <th>c3</th>\n",
       "      <th>s4</th>\n",
       "      <th>c4</th>\n",
       "      <th>s5</th>\n",
       "      <th>c5</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  s1  c1 s2  c2 s3  c3 s4  c4 s5  c5 class\n",
       "0  1  10  1  11  1  13  1  12  1   1     9\n",
       "1  2  11  2  13  2  10  2  12  2   1     9\n",
       "2  3  12  3  11  3  13  3  10  3   1     9\n",
       "3  4  10  4  11  4   1  4  13  4  12     9\n",
       "4  4   1  4  13  4  12  4  11  4  10     9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\n",
    "    URL_TO_TRAIN_DATA,\n",
    "    header=None,\n",
    "    names=COLUMNS_NAMES,\n",
    "    dtype={column_name: \"object\" for column_name in COLUMNS_NAMES}\n",
    ")\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных тестовой выборки средствами *Pandas*, вывод первых 5 строк таблицы на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>c1</th>\n",
       "      <th>s2</th>\n",
       "      <th>c2</th>\n",
       "      <th>s3</th>\n",
       "      <th>c3</th>\n",
       "      <th>s4</th>\n",
       "      <th>c4</th>\n",
       "      <th>s5</th>\n",
       "      <th>c5</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  s1  c1 s2  c2 s3  c3 s4  c4 s5  c5 class\n",
       "0  1  10  1  11  1  13  1  12  1   1     9\n",
       "1  2  11  2  13  2  10  2  12  2   1     9\n",
       "2  3  12  3  11  3  13  3  10  3   1     9\n",
       "3  4  10  4  11  4   1  4  13  4  12     9\n",
       "4  4   1  4  13  4  12  4  11  4  10     9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\n",
    "    URL_TO_TEST_DATA,\n",
    "    header=None,\n",
    "    names=COLUMNS_NAMES,\n",
    "    dtype={column_name: \"object\" for column_name in COLUMNS_NAMES}\n",
    ")\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Выводим базовую статистическую информацию по обучающей выборке. Поскольку мы знаем значения, которые будет принимать каждый из признаков, они являются дискретными и строго ограниченными, поэтому мы интерпретируем их как категориальные признаки.  \n",
    "* *count* - количество объектов, имеющих данный признак (замечаем, что они везде равны, т.е. пропущенные значения отсутствуют),\n",
    "* *unique* - количество уникальных значений признака,\n",
    "* *top* - самое часто встречающееся значение признака (мода признака),\n",
    "* *freq* - количество появлений значения, описанного в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>c1</th>\n",
       "      <th>s2</th>\n",
       "      <th>c2</th>\n",
       "      <th>s3</th>\n",
       "      <th>c3</th>\n",
       "      <th>s4</th>\n",
       "      <th>c4</th>\n",
       "      <th>s5</th>\n",
       "      <th>c5</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25010</td>\n",
       "      <td>25010</td>\n",
       "      <td>25010</td>\n",
       "      <td>25010</td>\n",
       "      <td>25010</td>\n",
       "      <td>25010</td>\n",
       "      <td>25010</td>\n",
       "      <td>25010</td>\n",
       "      <td>25010</td>\n",
       "      <td>25010</td>\n",
       "      <td>25010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6312</td>\n",
       "      <td>1982</td>\n",
       "      <td>6309</td>\n",
       "      <td>2007</td>\n",
       "      <td>6419</td>\n",
       "      <td>2000</td>\n",
       "      <td>6314</td>\n",
       "      <td>1999</td>\n",
       "      <td>6314</td>\n",
       "      <td>1994</td>\n",
       "      <td>12493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           s1     c1     s2     c2     s3     c3     s4     c4     s5     c5  \\\n",
       "count   25010  25010  25010  25010  25010  25010  25010  25010  25010  25010   \n",
       "unique      4     13      4     13      4     13      4     13      4     13   \n",
       "top         4      1      1     13      4     10      3      3      3      8   \n",
       "freq     6312   1982   6309   2007   6419   2000   6314   1999   6314   1994   \n",
       "\n",
       "        class  \n",
       "count   25010  \n",
       "unique     10  \n",
       "top         0  \n",
       "freq    12493  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичное действие проводим с тестовой выборкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>c1</th>\n",
       "      <th>s2</th>\n",
       "      <th>c2</th>\n",
       "      <th>s3</th>\n",
       "      <th>c3</th>\n",
       "      <th>s4</th>\n",
       "      <th>c4</th>\n",
       "      <th>s5</th>\n",
       "      <th>c5</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>250900</td>\n",
       "      <td>77282</td>\n",
       "      <td>250362</td>\n",
       "      <td>77373</td>\n",
       "      <td>250748</td>\n",
       "      <td>77517</td>\n",
       "      <td>250600</td>\n",
       "      <td>77581</td>\n",
       "      <td>250755</td>\n",
       "      <td>77566</td>\n",
       "      <td>501209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             s1       c1       s2       c2       s3       c3       s4  \\\n",
       "count   1000000  1000000  1000000  1000000  1000000  1000000  1000000   \n",
       "unique        4       13        4       13        4       13        4   \n",
       "top           3        6        1       11        3        7        3   \n",
       "freq     250900    77282   250362    77373   250748    77517   250600   \n",
       "\n",
       "             c4       s5       c5    class  \n",
       "count   1000000  1000000  1000000  1000000  \n",
       "unique       13        4       13       10  \n",
       "top           7        1        3        0  \n",
       "freq      77581   250755    77566   501209  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем каждую из имеющихся выборок на две части:  \n",
    "* *X* - часть, располагающая нецелевыми признаками, т.е. такими признаками, на основе которых будут происходить предсказания,\n",
    "* *y* - часть, содержащая целевые признаки (в данном случае он один - *class*) - ответы, которые требуется предсказывать и прогнозировать,  \n",
    "\n",
    "Методами *Pandas* производим описанное разделение и выводим размерности полученных массивов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25010, 10), (25010,), (1000000, 10), (1000000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = data_train.drop([\"class\"], axis=1), data_train[\"class\"]\n",
    "X_test, y_test = data_test.drop([\"class\"], axis=1), data_test[\"class\"]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что тестовая выборка имеет избыточное количество данных (их примерно в $40$ раз больше, чем обучающих), поэтому взять из них данные для проверки обучения нейронной сети (валидации) не составит труда, возьмем соотношение проверочных данных к тестовым $1:1$.  \n",
    "Произведем разделение и выведем размерности полученных массивов на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500000, 10), (500000,), (500000, 10), (500000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val, y_val = X_test[:X_test.shape[0] // 2], y_test[:y_test.shape[0] // 2]\n",
    "X_test, y_test = X_test[X_test.shape[0] // 2:], y_test[y_test.shape[0] // 2:]\n",
    "\n",
    "X_test.shape, y_test.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку все наши признаки являются дискретными категориальными, их нужно векторизировать, делается это следующим образом:  \n",
    "если имеется признак $\\ f $, имеющий множество значений $\\{v_1,\\ v_2, \\dots,\\ v_n \\},\\ n \\in \\mathbb{N}$, тогда мы делим признак $\\ f $ на множество признаков $\\big\\{f_{v_1},\\ f_{v_2}, \\dots,\\ f_{v_n} \\big\\}$, каждый из которых принимает значения из множества $\\{0, 1\\}$, указывающих на принадлежность объекта данных тому или иному значению первоначального признака.  \n",
    "Методами *Pandas* делаем такое преобразование данных и выводим размерности полученных массивов на экран. Замечаем, что $10$ нецелевых признаков преобразовались в $85$ бинарных числовых, а целевой признак *class* аналогично раздробился на $10$ признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25010, 85),\n",
       " (25010, 10),\n",
       " (500000, 85),\n",
       " (500000, 10),\n",
       " (500000, 85),\n",
       " (500000, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = pd.get_dummies(X_train), pd.get_dummies(y_train, prefix=COLUMNS_NAMES[-1])\n",
    "X_test, y_test = pd.get_dummies(X_test), pd.get_dummies(y_test, prefix=COLUMNS_NAMES[-1])\n",
    "X_val, y_val = pd.get_dummies(X_val), pd.get_dummies(y_val, prefix=COLUMNS_NAMES[-1])\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методами *Keras* с back-end *TensorFlow* конструируем архитектуру нейронной сети.  \n",
    "* *Sequential* - модель нейронной сети, в которой слои соединяются последовательно в строгом порядке,\n",
    "* *Dense* - т.н. полносвязный слой, т.е. слой нейронной сети, в котором все нейроны текущего уровня соединяются со всеми нейронами следующего уровня,  \n",
    "\n",
    "Архитектура такова:\n",
    "1. Первый, входной слой: возьмем количество нейронов величиной, равной количеству векторизированных нецелевых признаков, т.е. $85$, количество входов так же равно количеству нецелевых признаков - $85$, веса и смещения генерируются случайно с нормальным распределением, функция активации - *SoftPlus*,\n",
    "2. Второй, выходной слой: $10$ нейронов (или по-другому выходных сигналов), каждый из которых будет соответствовать вероятности принадлежности того или иного значения признака *class* обрабатываемому объетку, веса и смещения генерируются случайно с нормальным распределением, функция активации - *Sigmoid*.  \n",
    "\n",
    "Компилируем модель с такими параметрами:\n",
    "1. Функция потерь (*loss*) - категориальная перекрестная энтропия,\n",
    "2. Оптимизатор параметров нейронной сети (*optimizer*) - Adam,\n",
    "3. Метрики для оценки работы нейронной сети: точность (*accuracy*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Dense(\n",
    "        85, # number of neurons\n",
    "        input_dim=X_train.shape[1], # number of inputs\n",
    "        kernel_initializer=\"normal\", # weights initialization (maybe: \"zeros\", \"ones\", ... -> https://keras.io/initializers/)\n",
    "        activation=\"softplus\" # activation function (smooth ReLU), maybe: \"softmax\", \"relu\", \"tanh\", ... -> https://keras.io/activations/\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Dense(\n",
    "        10,\n",
    "        kernel_initializer=\"normal\",\n",
    "        activation=\"sigmoid\"\n",
    "    )\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", # loss function (maybe: \"categorical_hinge\", ... -> https://keras.io/losses/)\n",
    "    optimizer=\"adam\", # parameters optimizer (maybe: \"sgd\", \"adagrad\", ... -> https://keras.io/optimizers/)\n",
    "    metrics=[\"accuracy\"] # metrics for evaluation (maybe: \"categorical_accuracy\", ... -> https://keras.io/metrics/)\n",
    ")\n",
    "\n",
    "global_losses_history = {\n",
    "    \"loss\": [],\n",
    "    \"val_loss\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем нейронную сеть на обучающей выборке (*X_train*, *y_train*), с размером мини-выборки, равным длине самой выборки, используем данные для проверки работы нейронной сети в ходе обучения (*X_val*, *y_val*).  \n",
    "Из-за ограничений сервиса *PythonAnywhere* обучаем сеть в несколько заходов, по $1000$ эпох каждый.  \n",
    "В конце каждого захода выводится длительность обучения в секундах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25010 samples, validate on 500000 samples\n",
      "Epoch 1/1000\n",
      " - 5s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 2/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 3/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 4/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 5/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 6/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 7/1000\n",
      " - 3s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 8/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 9/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 10/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 11/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 12/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 13/1000\n",
      " - 6s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 14/1000\n",
      " - 4s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 15/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 16/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 17/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 18/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 19/1000\n",
      " - 4s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 20/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 21/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 22/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 23/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 24/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 25/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 26/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 27/1000\n",
      " - 3s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 28/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 29/1000\n",
      " - 5s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 30/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 31/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 32/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 33/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 34/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 35/1000\n",
      " - 4s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 36/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 37/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 38/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 39/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 40/1000\n",
      " - 2s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 41/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 42/1000\n",
      " - 1s - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 43/1000\n",
      " - 3s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 44/1000\n",
      " - 4s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 45/1000\n",
      " - 4s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 46/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 47/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 48/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 49/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 50/1000\n",
      " - 4s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 51/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 52/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 53/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 54/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 55/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 56/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 57/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 58/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 59/1000\n",
      " - 3s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 60/1000\n",
      " - 5s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 61/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 62/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 63/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 64/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 65/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 66/1000\n",
      " - 4s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 67/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 68/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 69/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 70/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 71/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 72/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 73/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 74/1000\n",
      " - 3s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 75/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1595 - val_acc: 0.9622\n",
      "Epoch 76/1000\n",
      " - 5s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 77/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 78/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 79/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 80/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 81/1000\n",
      " - 3s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 82/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 83/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 84/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 85/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 86/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 87/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 88/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9622\n",
      "Epoch 89/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 90/1000\n",
      " - 3s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 91/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 92/1000\n",
      " - 5s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 93/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 94/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 95/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 96/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 97/1000\n",
      " - 3s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 98/1000\n",
      " - 3s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 99/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 100/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 101/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 102/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 103/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 104/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 105/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 106/1000\n",
      " - 3s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 107/1000\n",
      " - 5s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 108/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 109/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 110/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 111/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 112/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 113/1000\n",
      " - 4s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 114/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 115/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 116/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 117/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 118/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 119/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 120/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 121/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 122/1000\n",
      " - 3s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 123/1000\n",
      " - 5s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 124/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 125/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 126/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 127/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 128/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 129/1000\n",
      " - 4s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 130/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 131/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 132/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 133/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 134/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 135/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 136/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 137/1000\n",
      " - 3s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 138/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 139/1000\n",
      " - 5s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 140/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 141/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 142/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 143/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 144/1000\n",
      " - 3s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 145/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 146/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 147/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 148/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 149/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 150/1000\n",
      " - 2s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 151/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 152/1000\n",
      " - 1s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 153/1000\n",
      " - 3s - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 154/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 155/1000\n",
      " - 4s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 156/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 157/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 158/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 159/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 160/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 161/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 162/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 163/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 164/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 165/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 166/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 167/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 168/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 169/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 170/1000\n",
      " - 5s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 171/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 172/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 173/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 174/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 175/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 176/1000\n",
      " - 4s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 177/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 178/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 179/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 180/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 181/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 182/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 183/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 184/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 185/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 186/1000\n",
      " - 5s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 187/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 188/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 189/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 190/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 191/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 192/1000\n",
      " - 4s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 193/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 194/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 195/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 196/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 197/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 198/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 199/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 200/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 201/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 202/1000\n",
      " - 5s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 203/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 204/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 205/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 206/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 207/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 208/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 209/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 210/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 211/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 212/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 213/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 214/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 215/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 216/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 217/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 218/1000\n",
      " - 4s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 219/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 220/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 221/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 222/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 223/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 224/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 225/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 226/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 227/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 228/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 229/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 230/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 231/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 232/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 233/1000\n",
      " - 5s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 234/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 235/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 236/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 237/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 238/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 239/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 240/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 241/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 242/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 243/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 244/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 245/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 246/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 247/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 248/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 249/1000\n",
      " - 5s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 250/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 251/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 252/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 253/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 254/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 255/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 256/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 257/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 258/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 259/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 260/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 261/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 262/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 263/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 264/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 265/1000\n",
      " - 5s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 266/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 267/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 268/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 269/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 270/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 271/1000\n",
      " - 3s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 272/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 273/1000\n",
      " - 2s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 274/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 275/1000\n",
      " - 1s - loss: 0.0715 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 276/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 277/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 278/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 279/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 280/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 281/1000\n",
      " - 5s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 282/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 283/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 284/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 285/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 286/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 287/1000\n",
      " - 4s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 288/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 289/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1596 - val_acc: 0.9623\n",
      "Epoch 290/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9623\n",
      "Epoch 291/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9623\n",
      "Epoch 292/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9623\n",
      "Epoch 293/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 294/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 295/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 296/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 297/1000\n",
      " - 5s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 298/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 299/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 300/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9623\n",
      "Epoch 301/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9623\n",
      "Epoch 302/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9623\n",
      "Epoch 303/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9623\n",
      "Epoch 304/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 305/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 306/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 307/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 308/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 309/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 310/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 311/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 312/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 313/1000\n",
      " - 4s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 314/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 315/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 316/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 317/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 318/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 319/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 320/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 321/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 322/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 323/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 324/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 325/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 326/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 327/1000\n",
      " - 4s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 328/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 329/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 330/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 331/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 332/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 333/1000\n",
      " - 4s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 334/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 335/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 336/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 337/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 338/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 339/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 340/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 341/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 342/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 343/1000\n",
      " - 5s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 344/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 345/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 346/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 347/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 348/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 349/1000\n",
      " - 4s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 350/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 351/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 352/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 353/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 354/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 355/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 356/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 357/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 358/1000\n",
      " - 5s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 359/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 360/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 361/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 362/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 363/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 364/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 365/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 366/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 367/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 368/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 369/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 370/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 371/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 372/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 373/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 374/1000\n",
      " - 5s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 375/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 376/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 377/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 378/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 379/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 380/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 381/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 382/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 383/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 384/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1597 - val_acc: 0.9624\n",
      "Epoch 385/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 386/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 387/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 388/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 389/1000\n",
      " - 4s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 390/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 391/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 392/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 393/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 394/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 395/1000\n",
      " - 4s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 396/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 397/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 398/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 399/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 400/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 401/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 402/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 403/1000\n",
      " - 1s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 404/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 405/1000\n",
      " - 4s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 406/1000\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 407/1000\n",
      " - 2s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 408/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 409/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 410/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 411/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 412/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 413/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 414/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 415/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 416/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 417/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 418/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 419/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 420/1000\n",
      " - 8s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 421/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 422/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 423/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 424/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 425/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 426/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 427/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 428/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 429/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 430/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 431/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 432/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 433/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 434/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 435/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 436/1000\n",
      " - 5s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 437/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 438/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 439/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 440/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 441/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 442/1000\n",
      " - 4s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 443/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 444/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 445/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 446/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 447/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 448/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 449/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 450/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9624\n",
      "Epoch 451/1000\n",
      " - 4s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 452/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 453/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 454/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 455/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 456/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 457/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 458/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 459/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 460/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 461/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 462/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 463/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 464/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 465/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 466/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 467/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 468/1000\n",
      " - 4s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 469/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 470/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 471/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 472/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 473/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 474/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 475/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 476/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 477/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 478/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 479/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 480/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 481/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 482/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 483/1000\n",
      " - 7s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 484/1000\n",
      " - 5s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 485/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 486/1000\n",
      " - 5s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 487/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 488/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 489/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 490/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 491/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 492/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 493/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 494/1000\n",
      " - 5s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 495/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 496/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 497/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 498/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 499/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 500/1000\n",
      " - 4s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 501/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 502/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 503/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 504/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 505/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 506/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 507/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 508/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 509/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 510/1000\n",
      " - 5s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 511/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 512/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 513/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 514/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 515/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 516/1000\n",
      " - 4s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 517/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 518/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 519/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 520/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 521/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 522/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 523/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 524/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 525/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 526/1000\n",
      " - 4s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 527/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 528/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 529/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 530/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 531/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 532/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 533/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 534/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 535/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 536/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 537/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 538/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 539/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 540/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 541/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 542/1000\n",
      " - 5s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 543/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 544/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 545/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 546/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 547/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 548/1000\n",
      " - 3s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 549/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 550/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 551/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 552/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 553/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 554/1000\n",
      " - 2s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 555/1000\n",
      " - 1s - loss: 0.0713 - acc: 0.9772 - val_loss: 0.1598 - val_acc: 0.9625\n",
      "Epoch 556/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 557/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 558/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 559/1000\n",
      " - 4s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 560/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 561/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 562/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 563/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 564/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 565/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 566/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 567/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 568/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 569/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 570/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 571/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 572/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 573/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 574/1000\n",
      " - 4s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 575/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 576/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 577/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 578/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 579/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9625\n",
      "Epoch 580/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 581/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 582/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 583/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 584/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 585/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 586/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 587/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 588/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 589/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 590/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 591/1000\n",
      " - 4s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 592/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 593/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 594/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 595/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 596/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 597/1000\n",
      " - 4s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 598/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 599/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 600/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 601/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 602/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 603/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 604/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 605/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 606/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 607/1000\n",
      " - 5s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 608/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 609/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 610/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 611/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 612/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 613/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 614/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 615/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 616/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 617/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 618/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 619/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 620/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 621/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 622/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 623/1000\n",
      " - 5s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 624/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 625/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 626/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 627/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 628/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 629/1000\n",
      " - 5s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 630/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 631/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 632/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 633/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 634/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 635/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 636/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 637/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 638/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 639/1000\n",
      " - 7s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 640/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 641/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 642/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 643/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 644/1000\n",
      " - 4s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 645/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 646/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 647/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 648/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 649/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 650/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 651/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 652/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 653/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 654/1000\n",
      " - 5s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 655/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 656/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 657/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 658/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 659/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 660/1000\n",
      " - 5s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 661/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 662/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 663/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 664/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 665/1000\n",
      " - 4s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 666/1000\n",
      " - 5s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 667/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 668/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 669/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 670/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 671/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 672/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 673/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 674/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 675/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 676/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 677/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 678/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 679/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 680/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 681/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 682/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 683/1000\n",
      " - 4s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 684/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 685/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 686/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 687/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 688/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 689/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 690/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 691/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 692/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 693/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 694/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 695/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 696/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 697/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 698/1000\n",
      " - 5s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 699/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 700/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 701/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 702/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 703/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 704/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 705/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 706/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 707/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 708/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 709/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 710/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 711/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 712/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 713/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 714/1000\n",
      " - 3s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 715/1000\n",
      " - 4s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 716/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 717/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 718/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 719/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 720/1000\n",
      " - 4s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 721/1000\n",
      " - 4s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 722/1000\n",
      " - 1s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 723/1000\n",
      " - 2s - loss: 0.0712 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 724/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9626\n",
      "Epoch 725/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 726/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 727/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 728/1000\n",
      " - 5s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 729/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 730/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 731/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 732/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 733/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 734/1000\n",
      " - 4s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 735/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 736/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 737/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1599 - val_acc: 0.9627\n",
      "Epoch 738/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 739/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 740/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 741/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 742/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 743/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 744/1000\n",
      " - 4s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 745/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 746/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 747/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 748/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 749/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 750/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 751/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 752/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 753/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 754/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 755/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 756/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 757/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 758/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 759/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 760/1000\n",
      " - 4s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 761/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 762/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 763/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 764/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 765/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 766/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 767/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 768/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 769/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 770/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 771/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 772/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 773/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 774/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 775/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 776/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 777/1000\n",
      " - 4s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 778/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 779/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 780/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 781/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 782/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 783/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 784/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 785/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 786/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 787/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 788/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 789/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 790/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 791/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 792/1000\n",
      " - 4s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 793/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 794/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 795/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 796/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 797/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 798/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 799/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 800/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 801/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 802/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 803/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 804/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 805/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 806/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 807/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 808/1000\n",
      " - 4s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 809/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 810/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 811/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 812/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 813/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 814/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 815/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 816/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 817/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 818/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 819/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 820/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 821/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 822/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 823/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 824/1000\n",
      " - 5s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 825/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 826/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 827/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 828/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 829/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 830/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 831/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 832/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 833/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 834/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 835/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 836/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 837/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 838/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 839/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 840/1000\n",
      " - 5s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 841/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 842/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 843/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 844/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 845/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 846/1000\n",
      " - 4s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 847/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 848/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 849/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 850/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 851/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 852/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 853/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 854/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 855/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 856/1000\n",
      " - 5s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 857/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 858/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 859/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 860/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 861/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 862/1000\n",
      " - 4s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 863/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 864/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 865/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 866/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 867/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 868/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 869/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 870/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 871/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 872/1000\n",
      " - 5s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 873/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 874/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 875/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 876/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1600 - val_acc: 0.9627\n",
      "Epoch 877/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 878/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 879/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 880/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 881/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 882/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 883/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 884/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 885/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 886/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 887/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 888/1000\n",
      " - 5s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 889/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 890/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 891/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 892/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 893/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 894/1000\n",
      " - 4s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 895/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 896/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 897/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 898/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 899/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 900/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 901/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 902/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 903/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 904/1000\n",
      " - 4s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 905/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 906/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 907/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 908/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 909/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 910/1000\n",
      " - 3s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 911/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 912/1000\n",
      " - 2s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 913/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 914/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 915/1000\n",
      " - 1s - loss: 0.0711 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 916/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 917/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 918/1000\n",
      " - 3s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 919/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 920/1000\n",
      " - 5s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 921/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 922/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 923/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 924/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 925/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 926/1000\n",
      " - 4s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 927/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 928/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 929/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 930/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 931/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 932/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 933/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 934/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 935/1000\n",
      " - 3s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 936/1000\n",
      " - 4s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 937/1000\n",
      " - 3s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 938/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 939/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 940/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 941/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 942/1000\n",
      " - 3s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 943/1000\n",
      " - 5s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 944/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 945/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 946/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 947/1000\n",
      " - 3s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 948/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 949/1000\n",
      " - 5s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 950/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 951/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 952/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 953/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 954/1000\n",
      " - 3s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 955/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 956/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 957/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 958/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 959/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 960/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 961/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9627\n",
      "Epoch 962/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 963/1000\n",
      " - 3s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 964/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 965/1000\n",
      " - 5s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 966/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 967/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 968/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 969/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 970/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 971/1000\n",
      " - 4s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 972/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 973/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 974/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 975/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 976/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 977/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 978/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 979/1000\n",
      " - 3s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 980/1000\n",
      " - 4s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 981/1000\n",
      " - 3s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 982/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 983/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 984/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 985/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 986/1000\n",
      " - 3s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 987/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 988/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 989/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 990/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 991/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 992/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 993/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 994/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 995/1000\n",
      " - 3s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 996/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1601 - val_acc: 0.9628\n",
      "Epoch 997/1000\n",
      " - 4s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1602 - val_acc: 0.9628\n",
      "Epoch 998/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1602 - val_acc: 0.9628\n",
      "Epoch 999/1000\n",
      " - 2s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1602 - val_acc: 0.9628\n",
      "Epoch 1000/1000\n",
      " - 1s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.1602 - val_acc: 0.9628\n",
      "Training runtime: 2369.5639960000044\n"
     ]
    }
   ],
   "source": [
    "from time import clock\n",
    "\n",
    "start = clock()\n",
    "\n",
    "fit_result = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=int(1 * X_train.shape[0]),\n",
    "    verbose=2, # results printing: 0 - not to print, 1 - print every epoch learning and result, 2 - print every epoch only result\n",
    "    validation_data=(\n",
    "        X_val,\n",
    "        y_val\n",
    "    )\n",
    ")\n",
    "\n",
    "global_losses_history[\"loss\"] += fit_result.history[\"loss\"]\n",
    "global_losses_history[\"val_loss\"] += fit_result.history[\"val_loss\"]\n",
    "\n",
    "print(\"Training runtime:\", clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAycAAAJBCAYAAABcc8paAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n108mD6nSVU4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5c995a710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"savefig.dpi\"] = 150\n",
    "\n",
    "plt.plot(\n",
    "    global_losses_history[\"loss\"],\n",
    "    label=\"training\"\n",
    ")\n",
    "plt.plot(\n",
    "    global_losses_history[\"val_loss\"],\n",
    "    \"--\",\n",
    "    label=\"validation\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.grid()\n",
    "plt.title(\"Losses\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "json_of_model = model.to_json()\n",
    "\n",
    "with open(\"pkr_model.json\", \"w\") as json_file:\n",
    "    json_file.write(json_of_model)\n",
    "\n",
    "model.save_weights(\"pkr_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03773199999999999"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error = 1 - model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "test_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
